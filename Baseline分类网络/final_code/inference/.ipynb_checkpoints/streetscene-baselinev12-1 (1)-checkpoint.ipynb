{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil, json\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1,2,3,4,5,6,7,8,9'\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "# 设置这个 flag 可以让内置的 cuDNN 的 auto-tuner 自动寻找最适合当前配置的高效算法，来达到优化运行效率的问题。\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "use_cuda = True\n",
    "my_test = False\n",
    "# 这里代表pseudo label训练4次\n",
    "epoch_num = 10\n",
    "\n",
    "WEIGHT_PATH = '../models/model_v29.pt'\n",
    "# '../input/streetclassify/model_v9.pt'\n",
    "TEST_PATH = '../input/test_a/*.png'\n",
    "INPUT_PATH = '../input'\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('logv30')\n",
    "\n",
    "\n",
    "# 定义读取数据集\n",
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # change\n",
    "        lbl = np.array(self.img_label[index][:4], dtype=np.int)\n",
    "        # 如果label不足5个，扩充为5个字符\n",
    "        lbl = list(lbl) + (4 - len(lbl)) * [10]\n",
    "        return img, torch.from_numpy(np.array(lbl[:4]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "\n",
    "# 定义分类模型，使用ResNet18进行特征提取\n",
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1, self).__init__()\n",
    "\n",
    "        model_conv = models.resnet18(pretrained=False)\n",
    "        model_conv.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
    "        self.cnn = model_conv\n",
    "        self.bn = nn.BatchNorm2d(512)\n",
    "        self.dp = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(512, 11)\n",
    "        self.fc2 = nn.Linear(512, 11)\n",
    "        self.fc3 = nn.Linear(512, 11)\n",
    "        self.fc4 = nn.Linear(512, 11)\n",
    "        # self.fc5 = nn.Linear(512, 11)\n",
    "\n",
    "    def forward(self, img):\n",
    "        feat = self.cnn(img)\n",
    "        feat = self.bn(feat)\n",
    "        feat = self.dp(feat)\n",
    "        feat = self.relu(feat)\n",
    "        # print(feat.shape)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        # c5 = self.fc5(feat)\n",
    "        return c1, c2, c3, c4\n",
    "\n",
    "\n",
    "# 训练与验证\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    # 切换模型为训练模式\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # change\n",
    "        target = target.long()\n",
    "        if use_cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        c0, c1, c2, c3 = model(input)\n",
    "#         loss = criterion(c0, target[:, 0]) + \\\n",
    "#                criterion(c1, target[:, 1]) + \\\n",
    "#                criterion(c2, target[:, 2]) + \\\n",
    "#                criterion(c3, target[:, 3])\n",
    "        loss = (1 - 0.17) * criterion(c0, target[:, 0]) + \\\n",
    "               (1 - 0.57) * criterion(c1, target[:, 1]) + \\\n",
    "               (1 - 0.23) * criterion(c2, target[:, 2]) + \\\n",
    "               (1 - 0.03) * criterion(c3, target[:, 3])\n",
    "        # criterion(c4, target[:, 4])\n",
    "\n",
    "        # loss /= 6\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def predict(test_loader, model, tta=10):\n",
    "    model.eval()\n",
    "    test_pred_tta = None\n",
    "\n",
    "    # TTA 次数\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(test_loader):\n",
    "                target = target.long()\n",
    "                if use_cuda:\n",
    "                    input = input.cuda()\n",
    "\n",
    "                c0, c1, c2, c3 = model(input)\n",
    "                if use_cuda:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.cpu().numpy(),\n",
    "                        c1.data.cpu().numpy(),\n",
    "                        c2.data.cpu().numpy(),\n",
    "                        c3.data.cpu().numpy()], axis=1)\n",
    "                    # c4.data.cpu().numpy()], axis=1)\n",
    "                else:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.numpy(),\n",
    "                        c1.data.numpy(),\n",
    "                        c2.data.numpy(),\n",
    "                        c3.data.numpy()], axis=1)\n",
    "                    # c4.data.numpy()], axis=1)\n",
    "\n",
    "                test_pred.append(output)\n",
    "\n",
    "        test_pred = np.vstack(test_pred)\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "\n",
    "    return test_pred_tta\n",
    "\n",
    "def predict2(test_loader, Models, tta=10):\n",
    "    for model in Models:\n",
    "        model.eval()\n",
    "        \n",
    "    test_pred_tta = None\n",
    "\n",
    "    # TTA 次数\n",
    "    for kk in range(tta):\n",
    "        test_pred = []\n",
    "        \n",
    "        model = Models[kk % len(Models)]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(test_loader):\n",
    "                target = target.long()\n",
    "                if use_cuda:\n",
    "                    input = input.cuda()\n",
    "                \n",
    "                c0, c1, c2, c3 = model(input)\n",
    "                if use_cuda:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.cpu().numpy(),\n",
    "                        c1.data.cpu().numpy(),\n",
    "                        c2.data.cpu().numpy(),\n",
    "                        c3.data.cpu().numpy()], axis=1)\n",
    "                    # c4.data.cpu().numpy()], axis=1)\n",
    "                else:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.numpy(),\n",
    "                        c1.data.numpy(),\n",
    "                        c2.data.numpy(),\n",
    "                        c3.data.numpy()], axis=1)\n",
    "                    # c4.data.numpy()], axis=1)\n",
    "\n",
    "                test_pred.append(output)\n",
    "\n",
    "        test_pred = np.vstack(test_pred)\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "\n",
    "    return test_pred_tta\n",
    "\n",
    "model = SVHN_Model1()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), 0.01)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.0005)\n",
    "# LR = 0.01\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=0.002, alpha=0.9)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "best_loss = 1000.0\n",
    "# 加载保存的最优模型\n",
    "model.load_state_dict(torch.load(WEIGHT_PATH))\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "# 预测并生成提交文件\n",
    "test_path = glob.glob(TEST_PATH)\n",
    "test_path.sort()\n",
    "# test_json = json.load(open('../input/test_a.json'))\n",
    "test_label = [[1]] * len(test_path)\n",
    "# print(len(test_path), len(test_label))\n",
    "\n",
    "\n",
    "############# PSEUDO #######################################\n",
    "\n",
    "best_loss = 1000.0\n",
    "\n",
    "train_path = glob.glob(f'{INPUT_PATH}/train/*.png')\n",
    "val_path = glob.glob(f'{INPUT_PATH}/val/*.png')\n",
    "image_path = train_path + val_path\n",
    "image_path.sort()\n",
    "\n",
    "train_json = json.load(open(f'{INPUT_PATH}/train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "val_json = json.load(open(f'{INPUT_PATH}/val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json]\n",
    "image_label = train_label + val_label\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(image_path, image_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.CenterCrop((60, 120)),\n",
    "#                     transforms.RandomCrop((50, 100)),\n",
    "                    transforms.Resize((64, 128)),\n",
    "#                     transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "#                     transforms.Grayscale(num_output_channels=3),\n",
    "                    transforms.RandomRotation(10),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])),\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "PSEUDO = True\n",
    "\n",
    "for epoch in tqdm(range(epoch_num)):\n",
    "\n",
    "    if PSEUDO is True:\n",
    "        \n",
    "        PSEUDO = False\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "        SVHNDataset(test_path, test_label,\n",
    "                    transforms.Compose([\n",
    "                        transforms.Resize((64, 128)),\n",
    "#                         transforms.CenterCrop((60, 120)),\n",
    "#                         transforms.Resize((64, 128)),\n",
    "    #                     transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "    #                     transforms.RandomRotation(25),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                    ])),\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        )\n",
    "\n",
    "        ####预测pseudo label\n",
    "        test_predict_label = predict(test_loader, model, 1)\n",
    "        test_predict_label = np.vstack([\n",
    "        test_predict_label[:, :11].argmax(1),\n",
    "        test_predict_label[:, 11:22].argmax(1),\n",
    "        test_predict_label[:, 22:33].argmax(1),\n",
    "        test_predict_label[:, 33:44].argmax(1),\n",
    "        # test_predict_label[:, 44:55].argmax(1),\n",
    "        ]).T\n",
    "            \n",
    "        test_label = test_predict_label\n",
    "        # 创建新的pesudo label     \n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            SVHNDataset(test_path, test_label,\n",
    "                        transforms.Compose([\n",
    "                        # transforms.RandomCrop((60, 120)),\n",
    "                            transforms.Resize((64, 128)),\n",
    "#                             transforms.CenterCrop((50, 100)),\n",
    "                            transforms.RandomCrop((60, 120)),\n",
    "                            transforms.Resize((64, 128)),\n",
    "    #                         transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "#                             transforms.Grayscale(num_output_channels=3),\n",
    "                            transforms.RandomRotation(10),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                        ])),\n",
    "            batch_size=128,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "        )\n",
    "\n",
    "    train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    test_loss = train(test_loader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    writer.add_scalar('Test/Loss', test_loss, epoch)\n",
    "    print(r'Epoch: {0}, Train loss: {1} \\t Test loss: {2}'.format(epoch, train_loss, test_loss))\n",
    "\n",
    "    # 记录下验证集精度\n",
    "    if train_loss < best_loss:\n",
    "        PSEUDO = True\n",
    "        best_loss = train_loss\n",
    "        print('Find better model in Epoch {0}, saving model.'.format(epoch))\n",
    "        torch.save(model.state_dict(), 'model_v30.pt')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('model_v30.pt'))\n",
    "\n",
    "model.load_state_dict(torch.load('../input/model-v23/model_v29.pt'))\n",
    "\n",
    "########################## END INFERENCE ##############################\n",
    "# 中心裁剪\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(test_path, test_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "#                     transforms.RandomCrop((50, 100)),\n",
    "                    transforms.CenterCrop((60, 120)),\n",
    "#                     transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "#                     transforms.RandomRotation(10),\n",
    "#                     transforms.RandomCrop((50, 100)),\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])),\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "# 不裁剪\n",
    "test_loader1 = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(test_path, test_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])),\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "# 随机裁剪\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(test_path, test_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "#                     transforms.FiveCrop((32,64)),\n",
    "#                     transforms.functional.crop(top=0, left=0, height=32, width=64),\n",
    "                    transforms.RandomCrop((32, 64)),\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])),\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "# test_predict_label = 50*predict(test_loader, model, 1)\n",
    "# test_predict_label += 50*predict(test_loader1, model, 1)\n",
    "# test_predict_label += predict(test_loader2, model, 10)\n",
    "test_predict_label = predict(test_loader, model, 1)\n",
    "\n",
    "# test_predict_label = predict2(test_loader, Models, 10)\n",
    "\n",
    "test_predict_label = np.vstack([\n",
    "    test_predict_label[:, :11].argmax(1),\n",
    "    test_predict_label[:, 11:22].argmax(1),\n",
    "    test_predict_label[:, 22:33].argmax(1),\n",
    "    test_predict_label[:, 33:44].argmax(1),\n",
    "    # test_predict_label[:, 44:55].argmax(1),\n",
    "]).T\n",
    "\n",
    "test_label_pred = []\n",
    "for x in test_predict_label:\n",
    "    test_label_pred.append(''.join(map(str, x[x != 10])))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_submit = pd.read_csv(f'{INPUT_PATH}/test_A_sample_submit.csv')\n",
    "df_submit['file_code'] = test_label_pred\n",
    "df_submit.to_csv('submit_v30.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/kaggle/working')\n",
    "# print(os.getcwd())\n",
    "# print(os.listdir(\"/kaggle/working\"))\n",
    "# from IPython.display import FileLink\n",
    "# FileLink('submit_v27.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
